{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_NlZJVio8QAJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import scipy.io\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twYw1Q_cB355",
        "outputId": "8ccf6316-5dfd-418c-c058-2cb3bbdb8eb5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#paths\n",
        "labels_path = \"/content/drive/MyDrive/oxford102/imagelabels.mat\"\n",
        "img_path = \"/content/drive/MyDrive/oxford102/flowers\"\n",
        "output_dir = \"/content/drive/MyDrive/oxford102/flower_dataset\""
      ],
      "metadata": {
        "id": "vkHgzdbBCMZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load labels\n",
        "labels = scipy.io.loadmat(labels_path)[\"labels\"][0]  # shape: (8189,)\n",
        "num_images = len(labels)  # should be 8189\n",
        "print(f\"Loaded {num_images} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhSkJvcGC9Pn",
        "outputId": "ae120fee-0339-4555-c545-322bd2ab5d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8189 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3ID7eD7fFFgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create class folders\n",
        "# ----------------------\n",
        "for class_id in range(1, 103):  # 102 classes, 1-indexed\n",
        "    class_folder = os.path.join(output_dir, str(class_id))\n",
        "    os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "# ----------------------\n",
        "# Copy images into folders\n",
        "# ----------------------\n",
        "for i, label in tqdm(enumerate(labels, start=1), total=num_images):\n",
        "    img_name = f\"image_{i:05d}.jpg\"  # adjust if needed (04d or no padding)\n",
        "    src = os.path.join(img_path, img_name)\n",
        "    dst = os.path.join(output_dir, str(label), img_name)\n",
        "\n",
        "    if os.path.exists(src):\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)  # <-- ensures class folder exists\n",
        "        shutil.copyfile(src, dst)\n",
        "    else:\n",
        "        print(f\"Missing file: {src}\")\n",
        "\n",
        "print(\"✅ Dataset organized for PyTorch ImageFolder!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFVjWrMDUyu",
        "outputId": "081701e4-ee4d-4b88-bb64-3d42fb468fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8189/8189 [40:21<00:00,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset organized for PyTorch ImageFolder!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "xOQOfINUGwtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Split\n",
        "\n",
        "labels_path = \"/content/drive/MyDrive/oxford102/imagelabels.mat\"\n",
        "img_path = \"/content/drive/MyDrive/oxford102/flowers\"\n",
        "output_dir = \"/content/drive/MyDrive/oxford102/flower_train_test\""
      ],
      "metadata": {
        "id": "-elhRuGFR7rh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = scipy.io.loadmat(labels_path)[\"labels\"][0]  # shape: (8189,)\n",
        "num_images = len(labels)\n",
        "print(f\"Loaded {num_images} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hDj-8DnSLaZ",
        "outputId": "ee3dab12-2c37-4296-e19f-ef6b37fd8828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8189 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratios = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}\n",
        "\n",
        "# ----------------------\n",
        "# Organize dataset\n",
        "# ----------------------\n",
        "for class_id in range(1, 103):  # 102 classes (1-indexed)\n",
        "    # find indices of images belonging to this class\n",
        "    indices = [i for i, lbl in enumerate(labels, start=1) if lbl == class_id]\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # split indices\n",
        "    n_total = len(indices)\n",
        "    n_train = int(n_total * split_ratios[\"train\"])\n",
        "    n_val = int(n_total * split_ratios[\"val\"])\n",
        "\n",
        "    train_idx = indices[:n_train]\n",
        "    val_idx = indices[n_train:n_train + n_val]\n",
        "    test_idx = indices[n_train + n_val:]\n",
        "\n",
        "    splits = {\"train\": train_idx, \"val\": val_idx, \"test\": test_idx}\n",
        "\n",
        "    for split_name, split_indices in splits.items():\n",
        "        for i in split_indices:\n",
        "            img_name = f\"image_{i:05d}.jpg\"  # adjust if your dataset uses 04d or no padding\n",
        "            src = os.path.join(img_path, img_name)\n",
        "            dst = os.path.join(output_dir, split_name, str(class_id), img_name)\n",
        "\n",
        "            if os.path.exists(src):\n",
        "                os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "                shutil.copyfile(src, dst)\n",
        "            else:\n",
        "                print(f\"Missing file: {src}\")\n",
        "\n",
        "print(\"✅ Dataset organized into train/val/test for ImageFolder!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "einu6J-aSEic",
        "outputId": "b039fb1a-27cb-4ab3-f145-7f8b275f4233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset organized into train/val/test for ImageFolder!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start training the Model"
      ],
      "metadata": {
        "id": "jClZ_P9VVfNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "pDwnYu0oSPb1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model: ResNet50\n",
        "\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2FNKfMaVqgJ",
        "outputId": "6958ffb9-f092-4363-f923-da102c755de2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 219MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = model.fc.in_features"
      ],
      "metadata": {
        "id": "roz8nzpDV7xa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512,102)\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint_path = \"/content/drive/MyDrive/oxford102/checkpoint_epoch5.pth\"\n",
        "model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "metadata": {
        "id": "dMRfB4olWLnV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "fuQoUZr3Yb45"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "Zk0mPkiGYqpJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "hf5_9fQSY5Ap"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/oxford102/flower_train_test/train\", transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = datasets.ImageFolder(\"/content/drive/MyDrive/oxford102/flower_train_test/val\", transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "3GsPrGjVZU1J"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(model,epochs):\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss=0.0\n",
        "    for b, (X,y) in enumerate(train_loader):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      y_pred = model(X)\n",
        "      loss = criterion(y_pred,y)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      if (b + 1) % 10 == 0:  # every 10 batches\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Batch [{b+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), f\"/content/drive/MyDrive/oxford102/checkpoint_epoch{epoch+1}.pth\")"
      ],
      "metadata": {
        "id": "4wvSK1ERZwYG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n"
      ],
      "metadata": {
        "id": "YnXGyY8sffVr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oAym0nvmOz0",
        "outputId": "28679ce8-1770-4466-b30d-5384d6430c0b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Batch [10/178], Loss: 4.4000\n",
            "Epoch [1/5], Batch [20/178], Loss: 4.1407\n",
            "Epoch [1/5], Batch [30/178], Loss: 4.3769\n",
            "Epoch [1/5], Batch [40/178], Loss: 4.0502\n",
            "Epoch [1/5], Batch [50/178], Loss: 4.1808\n",
            "Epoch [1/5], Batch [60/178], Loss: 3.6928\n",
            "Epoch [1/5], Batch [70/178], Loss: 4.0439\n",
            "Epoch [1/5], Batch [80/178], Loss: 3.9556\n",
            "Epoch [1/5], Batch [90/178], Loss: 3.9628\n",
            "Epoch [1/5], Batch [100/178], Loss: 4.0112\n",
            "Epoch [1/5], Batch [110/178], Loss: 3.8555\n",
            "Epoch [1/5], Batch [120/178], Loss: 3.7279\n",
            "Epoch [1/5], Batch [130/178], Loss: 3.7231\n",
            "Epoch [1/5], Batch [140/178], Loss: 3.7866\n",
            "Epoch [1/5], Batch [150/178], Loss: 3.5763\n",
            "Epoch [1/5], Batch [160/178], Loss: 3.5839\n",
            "Epoch [1/5], Batch [170/178], Loss: 3.6988\n",
            "Epoch 1/5, Loss: 3.9453\n",
            "Epoch [2/5], Batch [10/178], Loss: 3.1292\n",
            "Epoch [2/5], Batch [20/178], Loss: 3.2734\n",
            "Epoch [2/5], Batch [30/178], Loss: 3.2251\n",
            "Epoch [2/5], Batch [40/178], Loss: 3.1153\n",
            "Epoch [2/5], Batch [50/178], Loss: 3.3382\n",
            "Epoch [2/5], Batch [60/178], Loss: 2.9704\n",
            "Epoch [2/5], Batch [70/178], Loss: 2.9698\n",
            "Epoch [2/5], Batch [80/178], Loss: 3.2077\n",
            "Epoch [2/5], Batch [90/178], Loss: 3.0047\n",
            "Epoch [2/5], Batch [100/178], Loss: 2.9535\n",
            "Epoch [2/5], Batch [110/178], Loss: 2.7989\n",
            "Epoch [2/5], Batch [120/178], Loss: 3.0283\n",
            "Epoch [2/5], Batch [130/178], Loss: 2.9028\n",
            "Epoch [2/5], Batch [140/178], Loss: 2.8609\n",
            "Epoch [2/5], Batch [150/178], Loss: 2.9778\n",
            "Epoch [2/5], Batch [160/178], Loss: 2.8433\n",
            "Epoch [2/5], Batch [170/178], Loss: 2.8452\n",
            "Epoch 2/5, Loss: 3.0679\n",
            "Epoch [3/5], Batch [10/178], Loss: 2.4086\n",
            "Epoch [3/5], Batch [20/178], Loss: 2.6746\n",
            "Epoch [3/5], Batch [30/178], Loss: 2.8257\n",
            "Epoch [3/5], Batch [40/178], Loss: 2.3214\n",
            "Epoch [3/5], Batch [50/178], Loss: 2.4568\n",
            "Epoch [3/5], Batch [60/178], Loss: 2.6107\n",
            "Epoch [3/5], Batch [70/178], Loss: 2.2092\n",
            "Epoch [3/5], Batch [80/178], Loss: 2.6115\n",
            "Epoch [3/5], Batch [90/178], Loss: 2.6494\n",
            "Epoch [3/5], Batch [100/178], Loss: 2.3190\n",
            "Epoch [3/5], Batch [110/178], Loss: 2.6826\n",
            "Epoch [3/5], Batch [120/178], Loss: 2.4862\n",
            "Epoch [3/5], Batch [130/178], Loss: 2.5335\n",
            "Epoch [3/5], Batch [140/178], Loss: 2.2546\n",
            "Epoch [3/5], Batch [150/178], Loss: 2.7591\n",
            "Epoch [3/5], Batch [160/178], Loss: 2.4327\n",
            "Epoch [3/5], Batch [170/178], Loss: 2.1225\n",
            "Epoch 3/5, Loss: 2.4213\n",
            "Epoch [4/5], Batch [10/178], Loss: 1.9508\n",
            "Epoch [4/5], Batch [20/178], Loss: 1.9951\n",
            "Epoch [4/5], Batch [30/178], Loss: 2.1423\n",
            "Epoch [4/5], Batch [40/178], Loss: 1.5401\n",
            "Epoch [4/5], Batch [50/178], Loss: 2.2743\n",
            "Epoch [4/5], Batch [60/178], Loss: 2.4435\n",
            "Epoch [4/5], Batch [70/178], Loss: 1.8888\n",
            "Epoch [4/5], Batch [80/178], Loss: 2.3287\n",
            "Epoch [4/5], Batch [90/178], Loss: 1.5923\n",
            "Epoch [4/5], Batch [100/178], Loss: 1.9104\n",
            "Epoch [4/5], Batch [110/178], Loss: 1.7922\n",
            "Epoch [4/5], Batch [120/178], Loss: 2.1533\n",
            "Epoch [4/5], Batch [130/178], Loss: 1.9883\n",
            "Epoch [4/5], Batch [140/178], Loss: 1.7905\n",
            "Epoch [4/5], Batch [150/178], Loss: 1.9527\n",
            "Epoch [4/5], Batch [160/178], Loss: 2.1418\n",
            "Epoch [4/5], Batch [170/178], Loss: 1.5480\n",
            "Epoch 4/5, Loss: 1.9459\n",
            "Epoch [5/5], Batch [10/178], Loss: 1.7769\n",
            "Epoch [5/5], Batch [20/178], Loss: 1.8831\n",
            "Epoch [5/5], Batch [30/178], Loss: 1.9343\n",
            "Epoch [5/5], Batch [40/178], Loss: 1.4609\n",
            "Epoch [5/5], Batch [50/178], Loss: 1.7580\n",
            "Epoch [5/5], Batch [60/178], Loss: 1.0558\n",
            "Epoch [5/5], Batch [70/178], Loss: 1.9125\n",
            "Epoch [5/5], Batch [80/178], Loss: 1.5664\n",
            "Epoch [5/5], Batch [90/178], Loss: 1.9227\n",
            "Epoch [5/5], Batch [100/178], Loss: 1.2757\n",
            "Epoch [5/5], Batch [110/178], Loss: 1.1994\n",
            "Epoch [5/5], Batch [120/178], Loss: 1.7588\n",
            "Epoch [5/5], Batch [130/178], Loss: 1.6007\n",
            "Epoch [5/5], Batch [140/178], Loss: 1.6240\n",
            "Epoch [5/5], Batch [150/178], Loss: 1.5392\n",
            "Epoch [5/5], Batch [160/178], Loss: 1.3956\n",
            "Epoch [5/5], Batch [170/178], Loss: 1.3632\n",
            "Epoch 5/5, Loss: 1.6165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/oxford102/resnet50_flowers.pth\")"
      ],
      "metadata": {
        "id": "KFTVjVzJAZMS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "model.train()\n",
        "X, y = next(iter(train_loader))\n",
        "X, y = X.to(device), y.to(device)\n",
        "y_pred = model(X)\n",
        "loss = criterion(y_pred, y)\n",
        "print(\"Batch processed, loss:\", loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl6ynpazDwPh",
        "outputId": "b9a6176c-6c62-4daf-f1ec-f11bacd36418"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch processed, loss: 4.563467025756836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load in and test model accuracy"
      ],
      "metadata": {
        "id": "UIC0gRVTWUH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 102)\n",
        ")\n",
        "\n",
        "# Load trained weights\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/oxford102/resnet50_flowers.pth\"))\n",
        "model.to(device)\n",
        "\n",
        "# model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OKOJrSdWXqk",
        "outputId": "2c9b5ba7-ca86-4e93-ede8-c190c36ae4d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=102, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "flower_names = pd.read_csv('/content/drive/MyDrive/oxford102/oxford_flower_102_name.csv')\n",
        "flower_names.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pzbnjnf2W7-S",
        "outputId": "b93637b2-aa13-4199-970e-96e8ae846007"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Index                       Name\n",
              "0      0              pink primrose\n",
              "1      1  hard-leaved pocket orchid\n",
              "2      2           canterbury bells\n",
              "3      3                  sweet pea\n",
              "4      4           english marigold"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-465c2b82-ad4d-4ac1-bd90-53ad5af269b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pink primrose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>hard-leaved pocket orchid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>canterbury bells</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sweet pea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>english marigold</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-465c2b82-ad4d-4ac1-bd90-53ad5af269b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-465c2b82-ad4d-4ac1-bd90-53ad5af269b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-465c2b82-ad4d-4ac1-bd90-53ad5af269b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f99fb6a-264a-42a8-9371-a34afba0bcaa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f99fb6a-264a-42a8-9371-a34afba0bcaa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f99fb6a-264a-42a8-9371-a34afba0bcaa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "flower_names",
              "summary": "{\n  \"name\": \"flower_names\",\n  \"rows\": 102,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 0,\n        \"max\": 101,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          30,\n          67,\n          62\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"carnation\",\n          \"bearded iris\",\n          \"black-eyed susan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flowers = list(flower_names['Name'].unique())"
      ],
      "metadata": {
        "id": "AS1hgsuzX9e8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flowers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CWR-VkeYsrb",
        "outputId": "cebb260c-d8a2-4ee5-e9d2-7c27155ee186"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pink primrose',\n",
              " 'hard-leaved pocket orchid',\n",
              " 'canterbury bells',\n",
              " 'sweet pea',\n",
              " 'english marigold',\n",
              " 'tiger lily',\n",
              " 'moon orchid',\n",
              " 'bird of paradise',\n",
              " 'monkshood',\n",
              " 'globe thistle',\n",
              " 'snapdragon',\n",
              " \"colt's foot\",\n",
              " 'king protea',\n",
              " 'spear thistle',\n",
              " 'yellow iris',\n",
              " 'globe-flower',\n",
              " 'purple coneflower',\n",
              " 'peruvian lily',\n",
              " 'balloon flower',\n",
              " 'giant white arum lily',\n",
              " 'fire lily',\n",
              " 'pincushion flower',\n",
              " 'fritillary',\n",
              " 'red ginger',\n",
              " 'grape hyacinth',\n",
              " 'corn poppy',\n",
              " 'prince of wales feathers',\n",
              " 'stemless gentian',\n",
              " 'artichoke',\n",
              " 'sweet william',\n",
              " 'carnation',\n",
              " 'garden phlox',\n",
              " 'love in the mist',\n",
              " 'mexican aster',\n",
              " 'alpine sea holly',\n",
              " 'ruby-lipped cattleya',\n",
              " 'cape flower',\n",
              " 'great masterwort',\n",
              " 'siam tulip',\n",
              " 'lenten rose',\n",
              " 'barbeton daisy',\n",
              " 'daffodil',\n",
              " 'sword lily',\n",
              " 'poinsettia',\n",
              " 'bolero deep blue',\n",
              " 'wallflower',\n",
              " 'marigold',\n",
              " 'buttercup',\n",
              " 'oxeye daisy',\n",
              " 'common dandelion',\n",
              " 'petunia',\n",
              " 'wild pansy',\n",
              " 'primula',\n",
              " 'sunflower',\n",
              " 'pelargonium',\n",
              " 'bishop of llandaff',\n",
              " 'gaura',\n",
              " 'geranium',\n",
              " 'orange dahlia',\n",
              " 'pink-yellow dahlia',\n",
              " 'cautleya spicata',\n",
              " 'japanese anemone',\n",
              " 'black-eyed susan',\n",
              " 'silverbush',\n",
              " 'californian poppy',\n",
              " 'osteospermum',\n",
              " 'spring crocus',\n",
              " 'bearded iris',\n",
              " 'windflower',\n",
              " 'tree poppy',\n",
              " 'gazania',\n",
              " 'azalea',\n",
              " 'water lily',\n",
              " 'rose',\n",
              " 'thorn apple',\n",
              " 'morning glory',\n",
              " 'passion flower',\n",
              " 'lotus lotus',\n",
              " 'toad lily',\n",
              " 'anthurium',\n",
              " 'frangipani',\n",
              " 'clematis',\n",
              " 'hibiscus',\n",
              " 'columbine',\n",
              " 'desert-rose',\n",
              " 'tree mallow',\n",
              " 'magnolia',\n",
              " 'cyclamen',\n",
              " 'watercress',\n",
              " 'canna lily',\n",
              " 'hippeastrum',\n",
              " 'bee balm',\n",
              " 'ball moss',\n",
              " 'foxglove',\n",
              " 'bougainvillea',\n",
              " 'camellia',\n",
              " 'mallow',\n",
              " 'mexican petunia',\n",
              " 'bromelia',\n",
              " 'blanket flower',\n",
              " 'trumpet creeper',\n",
              " 'blackberry lily']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "6wIYlMePZVJ5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the test data\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "LtNRkozKZrpS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()  # set model to evaluation mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    max_batches = 20\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for i, (X, y) in enumerate(dataloader):\n",
        "        if i >= max_batches:\n",
        "          break  # stop after first `max_batches` batches\n",
        "        X,y = X.to(device), y.to(device)\n",
        "\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs,y)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        #predictions\n",
        "        _, preds = torch.max(outputs,1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    avg_loss = running_loss / len(dataloader)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "2uxrFoTvagXl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "evaluate(model, val_loader,criterion,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdsun2TQcMM4",
        "outputId": "569938dc-dc60-48fa-e125-e7fb0e5a137b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.7090, Accuracy: 76.25%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7089956065541819, 76.25)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing predictions\n"
      ],
      "metadata": {
        "id": "Jiz1cf-nf4GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X, device, class_names):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X = X.to(device)\n",
        "        outputs = model(X)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "    return [class_names[p] for p in preds.cpu().numpy()]"
      ],
      "metadata": {
        "id": "THHnbnSmcyh_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.ImageFolder(\"/content/drive/MyDrive/oxford102/flower_train_test/test\", transform=transform)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "e159_40Mf22m"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "idx = random.randint(0, len(test_data)-1)\n",
        "X, y = test_data[idx]\n",
        "print(idx)\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHxgkJqDgh3y",
        "outputId": "ec02da11-ea52-4616-cffc-007915588fff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "269\n",
            "tensor([[[0.1333, 0.1647, 0.2000,  ..., 0.0353, 0.0431, 0.0471],\n",
            "         [0.1176, 0.1490, 0.1882,  ..., 0.0353, 0.0431, 0.0471],\n",
            "         [0.1137, 0.1412, 0.1804,  ..., 0.0314, 0.0392, 0.0431],\n",
            "         ...,\n",
            "         [0.3961, 0.3922, 0.4039,  ..., 0.1647, 0.1608, 0.1882],\n",
            "         [0.4196, 0.4118, 0.4000,  ..., 0.1686, 0.1765, 0.2000],\n",
            "         [0.4157, 0.4118, 0.4039,  ..., 0.1882, 0.1961, 0.2078]],\n",
            "\n",
            "        [[0.2353, 0.2745, 0.3255,  ..., 0.0392, 0.0471, 0.0510],\n",
            "         [0.2118, 0.2510, 0.3059,  ..., 0.0392, 0.0471, 0.0510],\n",
            "         [0.1882, 0.2275, 0.2824,  ..., 0.0353, 0.0431, 0.0471],\n",
            "         ...,\n",
            "         [0.5686, 0.5647, 0.5765,  ..., 0.3255, 0.3255, 0.3569],\n",
            "         [0.5765, 0.5725, 0.5647,  ..., 0.3294, 0.3412, 0.3686],\n",
            "         [0.5686, 0.5686, 0.5647,  ..., 0.3451, 0.3569, 0.3765]],\n",
            "\n",
            "        [[0.0902, 0.1216, 0.1647,  ..., 0.0196, 0.0275, 0.0314],\n",
            "         [0.0706, 0.1020, 0.1490,  ..., 0.0196, 0.0275, 0.0314],\n",
            "         [0.0510, 0.0824, 0.1294,  ..., 0.0157, 0.0235, 0.0275],\n",
            "         ...,\n",
            "         [0.2863, 0.2824, 0.2863,  ..., 0.0941, 0.0902, 0.0941],\n",
            "         [0.3059, 0.3020, 0.2863,  ..., 0.0784, 0.0745, 0.0863],\n",
            "         [0.3059, 0.3059, 0.2902,  ..., 0.0863, 0.0784, 0.0863]]])\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVwr9N9Tgmfw",
        "outputId": "8ad66469-7eba-41ab-efe5-9861487c076e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.1333, 0.1647, 0.2000,  ..., 0.0353, 0.0431, 0.0471],\n",
              "          [0.1176, 0.1490, 0.1882,  ..., 0.0353, 0.0431, 0.0471],\n",
              "          [0.1137, 0.1412, 0.1804,  ..., 0.0314, 0.0392, 0.0431],\n",
              "          ...,\n",
              "          [0.3961, 0.3922, 0.4039,  ..., 0.1647, 0.1608, 0.1882],\n",
              "          [0.4196, 0.4118, 0.4000,  ..., 0.1686, 0.1765, 0.2000],\n",
              "          [0.4157, 0.4118, 0.4039,  ..., 0.1882, 0.1961, 0.2078]],\n",
              " \n",
              "         [[0.2353, 0.2745, 0.3255,  ..., 0.0392, 0.0471, 0.0510],\n",
              "          [0.2118, 0.2510, 0.3059,  ..., 0.0392, 0.0471, 0.0510],\n",
              "          [0.1882, 0.2275, 0.2824,  ..., 0.0353, 0.0431, 0.0471],\n",
              "          ...,\n",
              "          [0.5686, 0.5647, 0.5765,  ..., 0.3255, 0.3255, 0.3569],\n",
              "          [0.5765, 0.5725, 0.5647,  ..., 0.3294, 0.3412, 0.3686],\n",
              "          [0.5686, 0.5686, 0.5647,  ..., 0.3451, 0.3569, 0.3765]],\n",
              " \n",
              "         [[0.0902, 0.1216, 0.1647,  ..., 0.0196, 0.0275, 0.0314],\n",
              "          [0.0706, 0.1020, 0.1490,  ..., 0.0196, 0.0275, 0.0314],\n",
              "          [0.0510, 0.0824, 0.1294,  ..., 0.0157, 0.0235, 0.0275],\n",
              "          ...,\n",
              "          [0.2863, 0.2824, 0.2863,  ..., 0.0941, 0.0902, 0.0941],\n",
              "          [0.3059, 0.3020, 0.2863,  ..., 0.0784, 0.0745, 0.0863],\n",
              "          [0.3059, 0.3059, 0.2902,  ..., 0.0863, 0.0784, 0.0863]]]),\n",
              " 28)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With the code below we can use the test data to test unseen images."
      ],
      "metadata": {
        "id": "MdMXUsmYiXta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_data[205]\n",
        "\n",
        "# add batch dimension\n",
        "img = img.unsqueeze(0)  # shape: [1, C, H, W]\n",
        "\n",
        "# predict\n",
        "pred_name = predict(model, img, device, flowers)[0]\n",
        "\n",
        "print(f\"Predicted: {pred_name}, Actual: {flowers[label]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSIjWc_VhdsP",
        "outputId": "ce129dca-f1d0-416b-e16c-983fb29c820c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: fritillary, Actual: fritillary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwDKv-kCiHyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}